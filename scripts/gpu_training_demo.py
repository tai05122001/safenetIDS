#!/usr/bin/env python3
"""
Demo script Ä‘á»ƒ show cÃ¡ch tá»‘i Æ°u hÃ³a GPU training cho CNN+LSTM models
"""

import subprocess
import sys
from pathlib import Path

def show_gpu_options():
    """Hiá»ƒn thá»‹ cÃ¡c tÃ¹y chá»n GPU optimization"""
    print("=" * 80)
    print("ğŸš€ HÆ¯á»šNG DáºªN Tá»I Æ¯U HÃ“A GPU TRAINING CHO CNN+LSTM")
    print("=" * 80)

    print("\nğŸ“‹ CÃC TÃ™Y CHá»ŒN TÄ‚NG Tá»C Äá»˜ TRAINING:")
    print("1. --mixed-precision: Sá»­ dá»¥ng float16 thay vÃ¬ float32")
    print("   - TÄƒng tá»‘c 2-3x trÃªn GPU")
    print("   - Giáº£m memory usage 50%")
    print("   - Äá»™ chÃ­nh xÃ¡c tÆ°Æ¡ng Ä‘Æ°Æ¡ng")

    print("\n2. --xla: Enable XLA (Accelerated Linear Algebra)")
    print("   - Tá»‘i Æ°u hÃ³a graph execution")
    print("   - TÄƒng tá»‘c 10-50% trÃªn GPU")

    print("\n3. --gpu-memory-limit X: Giá»›i háº¡n GPU memory")
    print("   - VÃ­ dá»¥: --gpu-memory-limit 8 (8GB)")
    print("   - TrÃ¡nh out-of-memory errors")

    print("\n4. --gpu-device '0,1': Chá»‰ Ä‘á»‹nh GPU cá»¥ thá»ƒ")
    print("   - Multi-GPU training")
    print("   - Load balancing")

    print("\nğŸ’¡ Káº¾T Há»¢P Tá»I Æ¯U:")
    print("   --mixed-precision --xla --gpu-memory-limit 8")

def run_training_demo():
    """Demo training vá»›i GPU optimization"""

    print("\n" + "="*60)
    print("ğŸ¯ DEMO TRAINING Vá»šI GPU OPTIMIZATION")
    print("="*60)

    # Kiá»ƒm tra xem cÃ³ file dataset khÃ´ng
    dataset_file = "dataset_clean_cnn.pkl"
    if not Path(dataset_file).exists():
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y {dataset_file}")
        print("Cháº¡y scripts/preprocess_dataset.py --model-type both trÆ°á»›c")
        return

    # VÃ­ dá»¥ training vá»›i GPU optimization
    cmd = [
        sys.executable, "ids_pipeline/_1d_cnn/train_level1_cnn.py",
        "--source-dataset", dataset_file,
        "--output-dir", "artifacts_cnn_gpu_demo",
        "--epochs", "5",  # Ãt epochs cho demo
        "--batch-size", "64",
        "--mixed-precision",
        "--xla",
        "--gpu-memory-limit", "4",  # Giá»›i háº¡n 4GB cho demo
        "--auto-split"
    ]

    print("Cháº¡y lá»‡nh:")
    print(" ".join(cmd))
    print("\nğŸ“Š Mong Ä‘á»£i:")
    print("- Training trÃªn GPU vá»›i mixed precision")
    print("- XLA optimization enabled")
    print("- Memory limit 4GB")
    print("- Early stopping náº¿u cÃ³ GPU")

    try:
        print("\nğŸš€ Äang cháº¡y training demo...")
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        if result.returncode == 0:
            print("âœ… Training demo hoÃ n thÃ nh!")
        else:
            print(f"âš ï¸  Training káº¿t thÃºc vá»›i code: {result.returncode}")
            print("Log:", result.stderr[-500:])  # Last 500 chars

    except subprocess.TimeoutExpired:
        print("â° Training demo timeout (5 phÃºt)")
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")

def show_system_info():
    """Hiá»ƒn thá»‹ thÃ´ng tin system vÃ  GPU"""
    print("\n" + "="*60)
    print("ğŸ’» THÃ”NG TIN SYSTEM & GPU")
    print("="*60)

    try:
        import tensorflow as tf
        print(f"TensorFlow version: {tf.__version__}")
        print(f"CUDA built: {tf.test.is_built_with_cuda()}")
        print(f"cuDNN built: {tf.test.is_built_with_cudnn()}")

        gpus = tf.config.experimental.list_physical_devices('GPU')
        if gpus:
            print(f"âœ… GPU found: {len(gpus)} device(s)")
            for i, gpu in enumerate(gpus):
                details = tf.config.experimental.get_device_details(gpu)
                print(f"  GPU {i}: {details.get('device_name', 'Unknown')}")
        else:
            print("âŒ No GPU found - training will be slow on CPU")

    except ImportError:
        print("âŒ TensorFlow not installed")

def main():
    show_gpu_options()
    show_system_info()
    run_training_demo()

if __name__ == "__main__":
    main()
