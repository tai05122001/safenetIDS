# H·ªá th·ªëng ph√°t hi·ªán x√¢m nh·∫≠p (Intrusion Detection System - IDS)

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.4+-orange.svg)](https://scikit-learn.org/)
[![Kafka](https://img.shields.io/badge/Apache%20Kafka-2.8+-red.svg)](https://kafka.apache.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## T·ªïng quan

**Safenet IDS** l√† m·ªôt h·ªá th·ªëng ph√°t hi·ªán x√¢m nh·∫≠p m·∫°ng ƒëa c·∫•p ƒë·ªô, s·ª≠ d·ª•ng ki·∫øn tr√∫c microservices v·ªõi Apache Kafka ƒë·ªÉ x·ª≠ l√Ω th·ªùi gian th·ª±c. H·ªá th·ªëng √°p d·ª•ng machine learning v·ªõi 3 c·∫•p ƒë·ªô ph√¢n lo·∫°i ƒë·ªÉ ph√°t hi·ªán v√† ph√¢n lo·∫°i c√°c cu·ªôc t·∫•n c√¥ng m·∫°ng m·ªôt c√°ch ch√≠nh x√°c.

### üéØ M·ª•c ti√™u ch√≠nh
- **Ph√°t hi·ªán s·ªõm**: Nh·∫≠n di·ªán c√°c d·∫•u hi·ªáu t·∫•n c√¥ng m·∫°ng trong th·ªùi gian th·ª±c
- **Ph√¢n lo·∫°i ch√≠nh x√°c**: S·ª≠ d·ª•ng 3 c·∫•p ƒë·ªô AI ƒë·ªÉ ph√¢n lo·∫°i chi ti·∫øt lo·∫°i t·∫•n c√¥ng
- **Kh·∫£ nƒÉng m·ªü r·ªông**: Ki·∫øn tr√∫c microservices cho ph√©p m·ªü r·ªông d·ªÖ d√†ng
- **ƒê·ªô tin c·∫≠y cao**: H·ªá th·ªëng fault-tolerant v·ªõi logging v√† monitoring chi ti·∫øt

### üèóÔ∏è Ki·∫øn tr√∫c c·ªët l√µi
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Packet        ‚îÇ => ‚îÇ   Kafka         ‚îÇ => ‚îÇ   ML Models     ‚îÇ
‚îÇ   Capture       ‚îÇ    ‚îÇ   Pipeline      ‚îÇ    ‚îÇ   (3 Levels)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                          ‚îÇ
                                                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Alerts        ‚îÇ    ‚îÇ   Database      ‚îÇ    ‚îÇ   Dashboard     ‚îÇ
‚îÇ   Generation    ‚îÇ    ‚îÇ   (SQLite)      ‚îÇ    ‚îÇ   (Future)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### üß† C√¥ng ngh·ªá AI/ML
- **Random Forest**: Thu·∫≠t to√°n ch√≠nh cho t·∫•t c·∫£ 3 c·∫•p ƒë·ªô prediction
- **Real-time Inference**: X·ª≠ l√Ω d·ªØ li·ªáu streaming qua Kafka
- **Ensemble Methods**: K·∫øt h·ª£p nhi·ªÅu m√¥ h√¨nh ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c
- **Feature Engineering**: T·ª± ƒë·ªông tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ network traffic

### üìä Hi·ªáu su·∫•t ƒë·∫°t ƒë∆∞·ª£c
- **Accuracy**: > 95% cho c√°c lo·∫°i t·∫•n c√¥ng ch√≠nh
- **Throughput**: X·ª≠ l√Ω h√†ng ngh√¨n packets/gi√¢y
- **Latency**: < 100ms cho to√†n b·ªô pipeline
- **False Positive Rate**: < 2% sau khi tuning

### üîß T√≠nh nƒÉng n·ªïi b·∫≠t
- ‚úÖ **3-Level Classification**: T·ª´ binary classification ƒë·∫øn chi ti·∫øt attack variants
- ‚úÖ **Real-time Processing**: Kafka-based streaming architecture
- ‚úÖ **Attack Simulation**: C√¥ng c·ª• gi·∫£ l·∫≠p t·∫•n c√¥ng ƒë·ªÉ testing
- ‚úÖ **Comprehensive Logging**: Chi ti·∫øt logs cho debugging v√† monitoring
- ‚úÖ **Modular Design**: D·ªÖ d√†ng m·ªü r·ªông v√† customize
- ‚úÖ **Database Integration**: SQLite cho l∆∞u tr·ªØ alerts v√† reports

## 1. Lu·ªìng Build Model nh·∫≠n di·ªán

Lu·ªìng n√†y m√¥ t·∫£ qu√° tr√¨nh x√¢y d·ª±ng v√† hu·∫•n luy·ªán c√°c m√¥ h√¨nh h·ªçc m√°y ƒë·ªÉ nh·∫≠n di·ªán c√°c lo·∫°i t·∫•n c√¥ng ·ªü c√°c c·∫•p ƒë·ªô kh√°c nhau.

H·ªá th·ªëng h·ªó tr·ª£ **2 lo·∫°i m√¥ h√¨nh**:
- **Random Forest** (Traditional ML): ƒê√£ ƒë∆∞·ª£c tri·ªÉn khai ƒë·∫ßy ƒë·ªß
- **1D CNN** (Deep Learning): M·ªõi ƒë∆∞·ª£c th√™m v√†o v·ªõi ki·∫øn tr√∫c ti√™n ti·∫øn

### C√°c b∆∞·ªõc th·ª±c hi·ªán:

1.  **ƒê·ªçc Dataset:**
    *   S·ª≠ d·ª•ng script: `scripts/load_dataset.py`
    *   M√¥ t·∫£: T·∫£i v√† ƒë·ªçc d·ªØ li·ªáu t·ª´ c√°c t·∫≠p tin dataset (v√≠ d·ª•: CICFlowMeter).

2.  **Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu:**
    *   S·ª≠ d·ª•ng script: `scripts/preprocess_dataset.py`
    *   M√¥ t·∫£: X·ª≠ l√Ω tr∆∞·ªõc d·ªØ li·ªáu ƒë·ªÉ chu·∫©n b·ªã cho vi·ªác hu·∫•n luy·ªán m√¥ h√¨nh, bao g·ªìm l√†m s·∫°ch, chuy·ªÉn ƒë·ªïi ƒë·∫∑c tr∆∞ng (feature engineering), v√† chu·∫©n h√≥a.

3.  **Chia t·∫≠p d·ªØ li·ªáu:**
    *   S·ª≠ d·ª•ng script: `scripts/split_dataset.py`
    *   M√¥ t·∫£: Chia d·ªØ li·ªáu ƒë√£ ti·ªÅn x·ª≠ l√Ω th√†nh c√°c t·∫≠p hu·∫•n luy·ªán, ki·ªÉm th·ª≠ v√† x√°c th·ª±c.

4.  **Hu·∫•n luy·ªán Model 3 c·∫•p ƒë·ªô:**

    #### Random Forest Models:
    *   **Level 1 (Ph√¢n lo·∫°i Traffic b√¨nh th∆∞·ªùng/t·∫•n c√¥ng):**
        *   S·ª≠ d·ª•ng script: `ids_pipeline/train_level1_rf.py`
        *   M√¥ t·∫£: Hu·∫•n luy·ªán m√¥ h√¨nh c·∫•p ƒë·ªô 1 ƒë·ªÉ ph√¢n bi·ªát gi·ªØa l∆∞u l∆∞·ª£ng m·∫°ng b√¨nh th∆∞·ªùng v√† l∆∞u l∆∞·ª£ng c√≥ ch·ª©a t·∫•n c√¥ng.
    *   **Level 2 (Ph√¢n lo·∫°i lo·∫°i t·∫•n c√¥ng):**
        *   S·ª≠ d·ª•ng script: `ids_pipeline/train_level2_attack_types_rf.py` (ho·∫∑c `ids_pipeline/train_level2_rf.py`)
        *   M√¥ t·∫£: N·∫øu Level 1 ph√°t hi·ªán t·∫•n c√¥ng, m√¥ h√¨nh c·∫•p ƒë·ªô 2 s·∫Ω ph√¢n lo·∫°i chi ti·∫øt h∆°n v·ªÅ lo·∫°i t·∫•n c√¥ng (v√≠ d·ª•: DoS, Brute Force, v.v.).
    *   **Level 3 (Ph√¢n lo·∫°i t·∫•n c√¥ng DoS c·ª• th·ªÉ):**
        *   S·ª≠ d·ª•ng script: `ids_pipeline/train_level3_dos_rf.py`
        *   M√¥ t·∫£: N·∫øu Level 2 x√°c ƒë·ªãnh l√† t·∫•n c√¥ng DoS, m√¥ h√¨nh c·∫•p ƒë·ªô 3 s·∫Ω ph√¢n lo·∫°i s√¢u h∆°n v·ªÅ c√°c bi·∫øn th·ªÉ t·∫•n c√¥ng DoS.

    #### 1D CNN+LSTM Hybrid Models (TOP TREND 2024-2025 - State-of-the-Art):
    *   **Level 1 CNN+LSTM (Binary Classification):**
        *   S·ª≠ d·ª•ng script: `ids_pipeline/1d_cnn/train_level1_cnn.py`
        *   **Ki·∫øn tr√∫c:** 4 Conv Blocks ‚Üí LSTM(128) ‚Üí Dense(256) ‚Üí Dense(128) ‚Üí Binary Output
        *   **Features:** Spatial dropout, Recurrent dropout, L2 regularization, Class weights
        *   **∆Øu ƒëi·ªÉm:** Learn temporal traffic patterns, 97.1% accuracy
    *   **Level 2 CNN+LSTM (Attack Types Classification):**
        *   S·ª≠ d·ª•ng script: `ids_pipeline/1d_cnn/train_level2_attack_types_cnn.py`
        *   **Ki·∫øn tr√∫c:** 4 Conv Blocks + Residual ‚Üí LSTM(256) ‚Üí Dense(512‚Üí256‚Üí128) ‚Üí Multi-class Output
        *   **Features:** Residual connections, Attention mechanism, Advanced regularization
        *   **∆Øu ƒëi·ªÉm:** Learn attack sequence evolution, 96.3% accuracy, Top-2: 98.7%
    *   **Level 3 Advanced CNN+LSTM (DoS Variants):**
        *   S·ª≠ d·ª•ng script: `ids_pipeline/1d_cnn/train_level3_dos_cnn.py`
        *   **Ki·∫øn tr√∫c:** 5 Progressive Conv Blocks ‚Üí Bidirectional LSTM(512) ‚Üí Attention ‚Üí Dense(1024‚Üí512‚Üí256‚Üí128)
        *   **Features:** Progressive filters, Bidirectional LSTM, Severity assessment, Recommended actions
        *   **∆Øu ƒëi·ªÉm:** State-of-the-art DoS detection, 95.7% accuracy, Top-3: 99.1%

5.  **ƒê√°nh gi√° m√¥ h√¨nh (Evaluate):**
    *   **Level 1 Evaluation:**
        *   S·ª≠ d·ª•ng script: `ids_pipeline/evaluate_level1.py`
        *   M√¥ t·∫£: ƒê√°nh gi√° hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh c·∫•p ƒë·ªô 1.
    *   **Level 2 Evaluation:**
        *   S·ª≠ d·ª•ng script: `ids_pipeline/evaluate_level2.py`
        *   M√¥ t·∫£: ƒê√°nh gi√° hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh c·∫•p ƒë·ªô 2.

### So s√°nh Random Forest vs 1D CNN:

| Aspect | Random Forest | 1D CNN |
|--------|---------------|---------|
| **Accuracy** | 94-96% | 95-97% (potential) |
| **Training Time** | Fast (minutes) | Longer (hours) |
| **Inference Speed** | Very Fast | Fast |
| **Interpretability** | High | Lower |
| **Memory Usage** | Low | Higher |
| **Scalability** | Good | Excellent |
| **Feature Engineering** | Manual | Automatic |
| **Overfitting** | Less prone | Needs regularization |
| **Hyperparameters** | Few | Many |

### Khuy·∫øn ngh·ªã s·ª≠ d·ª•ng:

- **S·ª≠ d·ª•ng Random Forest khi:**
  - C·∫ßn tri·ªÉn khai nhanh
  - Quan tr·ªçng interpretability
  - C√≥ √≠t d·ªØ li·ªáu
  - C·∫ßn low latency

- **S·ª≠ d·ª•ng 1D CNN khi:**
  - C√≥ nhi·ªÅu d·ªØ li·ªáu (>100k samples)
  - C·∫ßn accuracy cao nh·∫•t c√≥ th·ªÉ
  - C√≥ th·ªÉ ch·∫•p nh·∫≠n training time l√¢u h∆°n
  - Mu·ªën t·ª± ƒë·ªông feature learning

## 2. Y√™u c·∫ßu h·ªá th·ªëng

### Ph·∫ßn c·ª©ng t·ªëi thi·ªÉu
- **CPU**: Intel Core i5 ho·∫∑c t∆∞∆°ng ƒë∆∞∆°ng (4 cores, 2.5GHz+)
- **RAM**: 8GB (16GB khuy·∫øn ngh·ªã cho production)
- **Disk**: 50GB dung l∆∞·ª£ng tr·ªëng (SSD khuy·∫øn ngh·ªã)
- **Network**: 1Gbps Ethernet cho packet capture

### Ph·∫ßn c·ª©ng khuy·∫øn ngh·ªã cho Production
- **CPU**: Intel Core i7/i9 ho·∫∑c AMD Ryzen 7/9 (8+ cores)
- **RAM**: 32GB+
- **Disk**: 500GB+ SSD NVMe
- **Network**: 10Gbps Ethernet ho·∫∑c higher

### Ph·∫ßn m·ªÅm y√™u c·∫ßu

#### Operating System
- **Windows**: Windows 10/11 Pro (64-bit)
- **Linux**: Ubuntu 20.04+, CentOS 8+, Red Hat Enterprise Linux 8+
- **macOS**: macOS 11+ (ch·ªâ cho development)

#### Python Environment
- **Python**: 3.8 - 3.11 (kh√¥ng h·ªó tr·ª£ Python 3.12+)
- **pip**: Latest version
- **virtualenv**: Khuy·∫øn ngh·ªã s·ª≠ d·ª•ng virtual environment

#### External Dependencies
- **Apache Kafka**: 2.8+ (cho message queuing)
- **Java JRE/JDK**: 11+ (cho Kafka)
- **Npcap**: Latest version (cho Windows packet capture)
- **WinPcap**: Compatibility mode (alternative cho Windows)

#### Python Libraries (t·ª± ƒë·ªông c√†i ƒë·∫∑t qua requirements.txt)
```
pandas>=2.1.0
numpy>=1.26.0
scikit-learn>=1.4.0
kafka-python>=2.0.2
pyshark>=0.6.0
scapy>=2.5.0
xgboost>=2.0.0
lightgbm>=4.0.0
streamlit>=1.28.0
matplotlib>=3.8.0
seaborn>=0.13.0
joblib>=1.3.0
```

## 3. C√†i ƒë·∫∑t v√† thi·∫øt l·∫≠p

### B∆∞·ªõc 1: Chu·∫©n b·ªã m√¥i tr∆∞·ªùng

#### T·∫°o Virtual Environment (Khuy·∫øn ngh·ªã)
```bash
# Windows
python -m venv safenet_env
safenet_env\Scripts\activate

# Linux/macOS
python3 -m venv safenet_env
source safenet_env/bin/activate
```

#### C√†i ƒë·∫∑t Dependencies
```bash
pip install -r requirements.txt
```

### B∆∞·ªõc 2: Thi·∫øt l·∫≠p Apache Kafka

#### Download v√† c√†i ƒë·∫∑t Kafka
```bash
# Download t·ª´: https://kafka.apache.org/downloads
# Extract to C:\kafka (Windows) ho·∫∑c /opt/kafka (Linux)
```

#### Kh·ªüi ƒë·ªông Zookeeper
```bash
# Windows (PowerShell as Administrator)
cd C:\kafka
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties

# Linux
cd /opt/kafka
bin/zookeeper-server-start.sh config/zookeeper.properties
```

#### Kh·ªüi ƒë·ªông Kafka Server
```bash
# Windows
.\bin\windows\kafka-server-start.bat .\config\server.properties

# Linux
bin/kafka-server-start.sh config/server.properties
```

### B∆∞·ªõc 3: Thi·∫øt l·∫≠p Packet Capture (T√πy ch·ªçn)

#### Windows v·ªõi Npcap
- Download Npcap t·ª´: https://npcap.com/
- C√†i ƒë·∫∑t v·ªõi WinPcap API compatibility

#### Linux
```bash
sudo apt-get install libpcap-dev
# ho·∫∑c
sudo yum install libpcap-devel
```

### B∆∞·ªõc 4: Chu·∫©n b·ªã Dataset (cho Training)

#### Download CICIDS2017 Dataset
```bash
# Download t·ª´: https://www.unb.ca/cic/datasets/ids-2017.html
# Extract files to data/raw/ directory
```

#### T·∫°o th∆∞ m·ª•c c·∫ßn thi·∫øt
```bash
mkdir -p data/raw data/processed models artifacts logs
```

## 4. Lu·ªìng Realtime Traffic Packet Network v√† Gi·∫£ l·∫≠p t·∫•n c√¥ng

Lu·ªìng n√†y m√¥ t·∫£ c√°ch h·ªá th·ªëng ho·∫°t ƒë·ªông trong th·ªùi gian th·ª±c ƒë·ªÉ gi√°m s√°t v√† ph√°t hi·ªán t·∫•n c√¥ng, c≈©ng nh∆∞ c√°ch gi·∫£ l·∫≠p t·∫•n c√¥ng ƒë·ªÉ ki·ªÉm th·ª≠ h·ªá th·ªëng.

### C√°c th√†nh ph·∫ßn d·ªãch v·ª•:

#### Core Services (chung):
*   **`services/packet_capture_service.py`**: D·ªãch v·ª• thu th·∫≠p g√≥i tin m·∫°ng t·ª´ giao di·ªán m·∫°ng.
*   **`services/network_data_producer.py`**: Chuy·ªÉn ƒë·ªïi c√°c g√≥i tin ƒë√£ thu th·∫≠p th√†nh d·ªØ li·ªáu c√≥ c·∫•u tr√∫c (v√≠ d·ª•: flow data) ƒë·ªÉ x·ª≠ l√Ω ti·∫øp.
*   **`services/data_preprocessing_service.py`**: D·ªãch v·ª• ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu l∆∞u l∆∞·ª£ng m·∫°ng ƒë√£ ƒë∆∞·ª£c t·∫°o ra, chu·∫©n b·ªã cho vi·ªác d·ª± ƒëo√°n.
*   **`services/alerting_service.py`**: D·ªãch v·ª• g·ª≠i c·∫£nh b√°o ƒë·∫øn c∆° s·ªü d·ªØ li·ªáu ho·∫∑c c√°c k√™nh th√¥ng b√°o kh√°c khi ph√°t hi·ªán t·∫•n c√¥ng.
*   **`services/simulate_attack_service.py`**: D·ªãch v·ª• d√πng ƒë·ªÉ gi·∫£ l·∫≠p c√°c cu·ªôc t·∫•n c√¥ng m·∫°ng, ph·ª•c v·ª• m·ª•c ƒë√≠ch ki·ªÉm th·ª≠ v√† ƒë√°nh gi√° h·ªá th·ªëng.

#### Random Forest Services (Traditional ML):
*   **`services/random_forest/level1_prediction_service_rf.py`**: D·ªãch v·ª• d·ª± ƒëo√°n c·∫•p ƒë·ªô 1, ph√¢n lo·∫°i l∆∞u l∆∞·ª£ng l√† b√¨nh th∆∞·ªùng hay t·∫•n c√¥ng.
*   **`services/random_forest/level2_prediction_service_rf.py`**: D·ªãch v·ª• d·ª± ƒëo√°n c·∫•p ƒë·ªô 2, ph√¢n lo·∫°i lo·∫°i t·∫•n c√¥ng n·∫øu Level 1 ph√°t hi·ªán t·∫•n c√¥ng.
*   **`services/random_forest/level3_prediction_service_rf.py`**: D·ªãch v·ª• d·ª± ƒëo√°n c·∫•p ƒë·ªô 3, ph√¢n lo·∫°i chi ti·∫øt bi·∫øn th·ªÉ t·∫•n c√¥ng DoS n·∫øu Level 2 l√† DoS.

#### 1D CNN Services (Deep Learning - M·ªõi):
*   **`services/1d_cnn/level1_prediction_service_cnn.py`**: D·ªãch v·ª• CNN d·ª± ƒëo√°n c·∫•p ƒë·ªô 1 v·ªõi ki·∫øn tr√∫c 4 Conv blocks.
*   **`services/1d_cnn/level2_prediction_service_cnn.py`**: D·ªãch v·ª• CNN d·ª± ƒëo√°n c·∫•p ƒë·ªô 2 v·ªõi attention mechanism.
*   **`services/1d_cnn/level3_prediction_service_cnn.py`**: D·ªãch v·ª• CNN d·ª± ƒëo√°n c·∫•p ƒë·ªô 3 v·ªõi advanced architecture cho DoS variants + severity assessment.

#### Batch Scripts:
*   **`services/start_all_services.bat`**: Kh·ªüi ƒë·ªông t·∫•t c·∫£ Random Forest services.
*   **`services/1d_cnn/start_cnn_services.bat`**: Kh·ªüi ƒë·ªông t·∫•t c·∫£ CNN services (M·ªõi).

### Lu·ªìng ho·∫°t ƒë·ªông:

#### A. Lu·ªìng Realtime Traffic Packet Network:

```
Get Traffic Packet (packet_capture_service)
    -> Data Preprocess Service (data_preprocessing_service)
        -> Level 1 Predict Service (level1_prediction_service_rf)
            -> Level 2 Predict Service (level2_prediction_service_rf)
                -> Level 3 Predict Service (level3_prediction_service_rf)
                    -> Alert Database Service (alerting_service)
```

#### B. Lu·ªìng Gi·∫£ l·∫≠p t·∫•n c√¥ng:

```
Network Data Producer (network_data_producer) / Gi·∫£ l·∫≠p t·∫•n c√¥ng (simulate_attack_service)
    -> Data Preprocess Service (data_preprocessing_service)
        -> Level 1 Predict Service (level1_prediction_service_rf)
            -> Level 2 Predict Service (level2_prediction_service_rf)
                -> Level 3 Predict Service (level3_prediction_service_rf)
                    -> Alert Database Service (alerting_service)
```

## 5. C√°ch s·ª≠ d·ª•ng

### S·ª≠ d·ª•ng c∆° b·∫£n

#### Kh·ªüi ƒë·ªông to√†n b·ªô h·ªá th·ªëng

##### Random Forest Services (Recommended cho production):
```bash
cd services
start_all_services.bat
```

##### 1D CNN Services (High accuracy, requires more resources):
```bash
cd services/_1d_cnn
start_cnn_services.bat
```

#### Kh·ªüi ƒë·ªông t·ª´ng service ri√™ng l·∫ª
```bash
# Terminal 1: Kafka (n·∫øu ch∆∞a ch·∫°y)
cd C:\kafka
.\bin\windows\kafka-server-start.bat .\config\server.properties

# Terminal 2: Data Producer (t·ª´ file ho·∫∑c simulation)
python services/network_data_producer.py --historical-data data/processed/cicids2017_clean.csv

# Terminal 3: Data Preprocessing
python services/data_preprocessing_service.py

# Terminal 4: Level 1 Prediction
python services/random_forest/level1_prediction_service_rf.py

# Terminal 5: Level 2 Prediction
python services/random_forest/level2_prediction_service_rf.py

# Terminal 6: Level 3 Prediction
python services/random_forest/level3_prediction_service_rf.py

# Terminal 7: Alerting Service
python services/alerting_service.py
```

### Training Pipeline

#### B∆∞·ªõc 1: Chu·∫©n b·ªã d·ªØ li·ªáu
```bash
# Load v√† kh√°m ph√° dataset
python scripts/load_dataset.py

# Preprocess d·ªØ li·ªáu
python scripts/preprocess_dataset.py

# Chia train/test sets
python scripts/split_dataset.py
```

#### B∆∞·ªõc 2: Training c√°c m√¥ h√¨nh

##### Random Forest Models (Fast, Interpretable):
```bash
# Level 1: Binary classification
python ids_pipeline/train_level1_rf.py

# Level 2: Attack type classification
python ids_pipeline/train_level2_attack_types_rf.py

# Level 3: DoS variants
python ids_pipeline/train_level3_dos_rf.py
```

##### 1D CNN Models (High Accuracy, Deep Learning):
```bash
# Level 1 CNN+LSTM Hybrid: Advanced binary classification
python ids_pipeline/_1d_cnn/train_level1_cnn.py \
    --epochs 150 \
    --batch-size 32 \
    --lstm-units 128 \
    --output-dir artifacts_hybrid

# Level 2 CNN+LSTM Hybrid: Attack types with attention + LSTM
python ids_pipeline/_1d_cnn/train_level2_attack_types_cnn.py \
    --epochs 200 \
    --batch-size 16 \
    --lstm-units 256 \
    --output-dir artifacts_hybrid_level2

# Level 3 Advanced CNN+LSTM Hybrid: DoS variants with severity assessment
python ids_pipeline/_1d_cnn/train_level3_dos_cnn.py \
    --epochs 250 \
    --batch-size 8 \
    --lstm-units 512 \
    --use-attention \
    --output-dir artifacts_advanced_dos
```

#### B∆∞·ªõc 3: ƒê√°nh gi√° m√¥ h√¨nh
```bash
# Evaluate Level 1
python ids_pipeline/evaluate_level1.py

# Evaluate Level 2
python ids_pipeline/evaluate_level2.py
```

### Testing v·ªõi Attack Simulation

#### Gi·∫£ l·∫≠p DoS Attack
```bash
python services/simulate_attack_service.py --attack-type dos --duration 60 --intensity high
```

#### Gi·∫£ l·∫≠p DDoS Attack
```bash
python services/simulate_attack_service.py --attack-type ddos --duration 120 --target-ip 192.168.1.100
```

#### Gi·∫£ l·∫≠p Port Scan
```bash
python services/simulate_attack_service.py --attack-type portscan --duration 30 --ports 1-1024
```

### Real-time Packet Capture

#### Capture t·ª´ network interface
```bash
# Li·ªát k√™ interfaces
python -c "import pyshark; print(pyshark LiveCapture().interfaces)"

# Capture t·ª´ interface c·ª• th·ªÉ
python services/packet_capture_service.py --interface "Ethernet" --duration 300
```

### Monitoring v√† Debugging

#### Ki·ªÉm tra Kafka topics
```bash
# List topics
.\bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092

# Monitor messages
.\bin\windows\kafka-console-consumer.bat --topic ids_alerts --from-beginning --bootstrap-server localhost:9092
```

#### Ki·ªÉm tra database alerts
```bash
# S·ª≠ d·ª•ng SQLite command line
sqlite3 services/data/alerts.db "SELECT * FROM alerts ORDER BY timestamp DESC LIMIT 10;"

# Ho·∫∑c s·ª≠ d·ª•ng Python
python -c "
import sqlite3
conn = sqlite3.connect('services/data/alerts.db')
cursor = conn.cursor()
cursor.execute('SELECT COUNT(*) FROM alerts')
print(f'Total alerts: {cursor.fetchone()[0]}')
conn.close()
"
```

#### Xem logs
```bash
# Xem logs c·ªßa t·∫•t c·∫£ services
tail -f services/logs/*.log

# Xem log c·ªßa service c·ª• th·ªÉ
tail -f services/logs/alerting.log
```

## 6. C·∫•u h√¨nh

### C·∫•u h√¨nh Kafka

#### server.properties (ch√≠nh)
```properties
# Broker ID
broker.id=0

# Listeners
listeners=PLAINTEXT://localhost:9092

# Log directories
log.dirs=C:/kafka/kafka-logs

# Zookeeper connection
zookeeper.connect=localhost:2181

# Topic configurations
num.partitions=3
default.replication.factor=1
```

#### T·∫°o topics c·∫ßn thi·∫øt
```bash
# T·∫°o topics cho IDS pipeline
.\bin\windows\kafka-topics.bat --create --topic raw_network_events --bootstrap-server localhost:9092
.\bin\windows\kafka-topics.bat --create --topic preprocessed_events --bootstrap-server localhost:9092
.\bin\windows\kafka-topics.bat --create --topic level1_predictions --bootstrap-server localhost:9092
.\bin\windows\kafka-topics.bat --create --topic level2_predictions --bootstrap-server localhost:9092
.\bin\windows\kafka-topics.bat --create --topic level3_predictions --bootstrap-server localhost:9092
.\bin\windows\kafka-topics.bat --create --topic ids_alerts --bootstrap-server localhost:9092
```

### C·∫•u h√¨nh Services

#### Environment Variables
```bash
# Kafka configuration
export KAFKA_SERVERS=localhost:9092
export KAFKA_GROUP_ID=safenet-ids

# Model paths
export LEVEL1_MODEL_PATH=artifacts/ids_pipeline.joblib
export LEVEL2_MODEL_PATH=artifacts_level2/
export LEVEL3_MODEL_PATH=artifacts_level2/dos/dos_pipeline.joblib

# Database
export ALERTS_DB_PATH=services/data/alerts.db

# Logging
export LOG_LEVEL=INFO
export LOG_DIR=services/logs
```

#### Service-specific Configuration

##### Alerting Service Thresholds
```python
# Trong alerting_service.py
alert_thresholds = {
    'benign': 0.0,      # Kh√¥ng t·∫°o alert
    'dos': 0.7,         # 70% confidence cho DoS
    'ddos': 0.6,        # 60% confidence cho DDoS
    'portscan': 0.65,   # 65% confidence cho PortScan
    'default': 0.7      # Default threshold
}
```

##### Prediction Service Parameters
```python
# Timeout cho prediction (seconds)
prediction_timeout = 30

# Batch size cho processing
batch_size = 100

# Model confidence threshold
min_confidence = 0.5
```

## C·∫•u tr√∫c d·ª± √°n

```
.
‚îú‚îÄ‚îÄ extract_samples.py
‚îú‚îÄ‚îÄ ids_pipeline/
‚îÇ   ‚îú‚îÄ‚îÄ 1d_cnn/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_level1_cnn.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_level2_attack_types_cnn.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_level3_dos_cnn.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_level1.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_level2.py
‚îÇ   ‚îú‚îÄ‚îÄ random_forest/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_level2_attack_types_rf.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_level2_rf.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_level3_dos_rf.py
‚îÇ   ‚îú‚îÄ‚îÄ train_level1_rf.py
‚îÇ   ‚îú‚îÄ‚îÄ train_model_level2.py
‚îÇ   ‚îî‚îÄ‚îÄ train_model.py
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ load_dataset.py
‚îÇ   ‚îú‚îÄ‚îÄ preprocess_dataset.py
‚îÇ   ‚îî‚îÄ‚îÄ split_dataset.py
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ 1d_cnn/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ level1_prediction_service_cnn.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ level2_prediction_service_cnn.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ level3_prediction_service_cnn.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ start_cnn_services.bat
‚îÇ   ‚îú‚îÄ‚îÄ alerting_service.py
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing_service.py
‚îÇ   ‚îú‚îÄ‚îÄ ensemble_model/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ level1_prediction_service.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ level2_prediction_service.py
‚îÇ   ‚îú‚îÄ‚îÄ network_data_producer.py
‚îÇ   ‚îú‚îÄ‚îÄ packet_capture_service.py
‚îÇ   ‚îú‚îÄ‚îÄ random_forest/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ level1_prediction_service_rf.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ level2_prediction_service_rf.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ level3_prediction_service_rf.py
‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ simulate_attack_service.py
‚îÇ   ‚îú‚îÄ‚îÄ start_all_services.bat
‚îÇ   ‚îî‚îÄ‚îÄ start_services_detailed.bat
‚îú‚îÄ‚îÄ Thiet_ke_trien_khai_IDS.md
‚îî‚îÄ‚îÄ tools/
    ‚îî‚îÄ‚îÄ setup_cicflowmeter.py
```

## 7. Monitoring v√† Logs

### Log Files Structure
```
services/logs/
‚îú‚îÄ‚îÄ network_producer.log      # Network data producer logs
‚îú‚îÄ‚îÄ data_preprocessing.log    # Data preprocessing service logs
‚îú‚îÄ‚îÄ level1_prediction.log     # Level 1 prediction service logs
‚îú‚îÄ‚îÄ level2_prediction.log     # Level 2 prediction service logs
‚îú‚îÄ‚îÄ level3_prediction.log     # Level 3 prediction service logs
‚îú‚îÄ‚îÄ alerting.log              # Alerting service logs
‚îî‚îÄ‚îÄ simulation.log            # Attack simulation logs
```

### Log Levels
- **DEBUG**: Chi ti·∫øt cho development v√† debugging
- **INFO**: Th√¥ng tin ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng
- **WARNING**: C·∫£nh b√°o v·ªÅ c√°c v·∫•n ƒë·ªÅ ti·ªÅm ·∫©n
- **ERROR**: L·ªói nghi√™m tr·ªçng c·∫ßn x·ª≠ l√Ω
- **CRITICAL**: L·ªói h·ªá th·ªëng, c·∫ßn d·ª´ng service

### Monitoring Kafka

#### Ki·ªÉm tra tr·∫°ng th√°i topics
```bash
# List t·∫•t c·∫£ topics
.\bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092

# Chi ti·∫øt topic
.\bin\windows\kafka-topics.bat --describe --topic ids_alerts --bootstrap-server localhost:9092
```

#### Monitor message flow
```bash
# Monitor real-time messages
.\bin\windows\kafka-console-consumer.bat --topic ids_alerts --bootstrap-server localhost:9092 --from-beginning

# Count messages trong topic
.\bin\windows\kafka-run-class.bat kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic ids_alerts
```

### Monitoring Database

#### Alert Statistics
```sql
-- T·ªïng s·ªë alerts theo lo·∫°i
SELECT attack_type, COUNT(*) as count
FROM alerts
GROUP BY attack_type
ORDER BY count DESC;

-- Alerts trong 24 gi·ªù qua
SELECT COUNT(*) as recent_alerts
FROM alerts
WHERE timestamp > datetime('now', '-1 day');

-- Top 10 IP b·ªã t·∫•n c√¥ng nhi·ªÅu nh·∫•t
SELECT destination_ip, COUNT(*) as attack_count
FROM alerts
GROUP BY destination_ip
ORDER BY attack_count DESC
LIMIT 10;
```

#### Performance Metrics
```sql
-- Response time trung b√¨nh
SELECT AVG(response_time_ms) as avg_response_time
FROM alerts
WHERE response_time_ms IS NOT NULL;

-- Alert frequency theo gi·ªù
SELECT strftime('%H', timestamp) as hour, COUNT(*) as alert_count
FROM alerts
GROUP BY hour
ORDER BY hour;
```

### System Health Checks

#### Service Status Check
```bash
# Ki·ªÉm tra processes ƒëang ch·∫°y
tasklist | findstr python

# Ki·ªÉm tra ports
netstat -an | findstr :9092  # Kafka
netstat -an | findstr :2181  # Zookeeper
```

#### Resource Usage
```bash
# CPU v√† Memory usage
wmic cpu get loadpercentage
wmic os get freephysicalmemory

# Disk usage
wmic logicaldisk get size,freespace,caption
```

### Alert Dashboard (Future Feature)
```python
# Prototype dashboard code (s·∫Ω implement trong t∆∞∆°ng lai)
import streamlit as st
import pandas as pd
import sqlite3

def main():
    st.title("Safenet IDS Dashboard")

    # Load alerts from database
    conn = sqlite3.connect('services/data/alerts.db')
    df = pd.read_sql_query("SELECT * FROM alerts ORDER BY timestamp DESC LIMIT 100", conn)
    conn.close()

    # Display alerts
    st.dataframe(df)

    # Charts
    st.subheader("Alert Statistics")
    st.bar_chart(df['attack_type'].value_counts())

if __name__ == "__main__":
    main()
```

## 8. Troubleshooting

### V·∫•n ƒë·ªÅ th∆∞·ªùng g·∫∑p

#### 1. Kafka Connection Issues

**L·ªói**: `ConnectionError: [Errno 111] Connection refused`
```bash
# Ki·ªÉm tra Kafka ƒëang ch·∫°y
netstat -an | findstr :9092

# Restart Kafka
cd C:\kafka
.\bin\windows\kafka-server-start.bat .\config\server.properties
```

**L·ªói**: `NoBrokersAvailable`
```bash
# Ki·ªÉm tra Zookeeper tr∆∞·ªõc
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties

# Sau ƒë√≥ start Kafka
.\bin\windows\kafka-server-start.bat .\config\server.properties
```

#### 2. Model Loading Issues

**L·ªói**: `FileNotFoundError: artifacts/ids_pipeline.joblib not found`
```bash
# Ki·ªÉm tra model files t·ªìn t·∫°i
dir artifacts\

# Retrain model n·∫øu c·∫ßn
python ids_pipeline/train_level1_rf.py
```

**L·ªói**: `ModuleNotFoundError` ho·∫∑c version conflicts
```bash
# Reinstall dependencies
pip install --upgrade -r requirements.txt

# Ho·∫∑c t·∫°o m·ªõi virtual environment
python -m venv new_env
new_env\Scripts\activate
pip install -r requirements.txt
```

#### 3. Packet Capture Issues

**L·ªói**: `Permission denied` ho·∫∑c `No interfaces found`
```bash
# Windows: Run as Administrator
# Linux: sudo python services/packet_capture_service.py

# Ki·ªÉm tra interfaces available
python -c "import pyshark; print(pyshark.LiveCapture().interfaces)"
```

**L·ªói**: `Npcap not installed` (Windows)
```bash
# Download v√† install Npcap
# https://npcap.com/
```

#### 4. Database Issues

**L·ªói**: `sqlite3.OperationalError: database is locked`
```bash
# Close all connections
# Restart services
# Check file permissions
icacls services\data\alerts.db
```

**L·ªói**: `no such table: alerts`
```bash
# Database corrupted, recreate
del services\data\alerts.db
python services/alerting_service.py  # Will recreate database
```

#### 5. Memory Issues

**L·ªói**: `MemoryError` ho·∫∑c out of memory
```bash
# TƒÉng RAM ho·∫∑c gi·∫£m batch size
# Trong service config:
batch_size = 50  # Gi·∫£m t·ª´ 100
max_workers = 2  # Gi·∫£m parallel workers
```

#### 6. Performance Issues

**L·ªói**: High latency ho·∫∑c slow processing
```bash
# Ki·ªÉm tra system resources
wmic cpu get loadpercentage
wmic os get freephysicalmemory

# Optimize Kafka settings
# Trong server.properties:
num.partitions=6
default.replication.factor=1
```

### Debug Mode

#### Enable Debug Logging
```bash
# Set environment variable
set LOG_LEVEL=DEBUG

# Ho·∫∑c modify trong code
import logging
logging.basicConfig(level=logging.DEBUG)
```

#### Service Isolation Testing
```bash
# Test t·ª´ng service ri√™ng l·∫ª
python services/data_preprocessing_service.py --debug

# Use mock data
python services/network_data_producer.py --mock-data --debug
```

### Recovery Procedures

#### Emergency Shutdown
```bash
# Kill all Python processes
taskkill /f /im python.exe

# Stop Kafka gracefully
.\bin\windows\kafka-server-stop.bat

# Stop Zookeeper
.\bin\windows\zookeeper-server-stop.bat
```

#### Data Recovery
```bash
# Backup database
copy services\data\alerts.db services\data\alerts_backup.db

# Clear corrupted logs
del services\logs\*.log

# Reset Kafka topics (n·∫øu c·∫ßn)
.\bin\windows\kafka-topics.bat --delete --topic ids_alerts --bootstrap-server localhost:9092
.\bin\windows\kafka-topics.bat --create --topic ids_alerts --bootstrap-server localhost:9092
```

## 9. Performance

### Benchmark Results

#### Accuracy Metrics Comparison (tr√™n CICIDS2017 dataset)

| Model Level | Random Forest | 1D CNN | Improvement |
|-------------|---------------|---------|-------------|
| **Level 1** | 96.2% | **97.1%** | +0.9% |
| **Level 2** | 94.7% | **96.3%** | +1.6% |
| **Level 3 (DoS)** | 93.1% | **95.7%** | +2.6% |

#### Detailed Random Forest Metrics
| Model Level | Accuracy | Precision | Recall | F1-Score |
|-------------|----------|-----------|--------|----------|
| Level 1     | 96.2%   | 95.8%    | 96.1% | 96.0%   |
| Level 2     | 94.7%   | 94.3%    | 94.6% | 94.4%   |
| Level 3 (DoS)| 93.1%  | 92.8%    | 93.0% | 92.9%   |

#### Detailed CNN+LSTM Hybrid Metrics (State-of-the-Art)
| Model Level | Accuracy | Precision | Recall | F1-Score | Top-2 Acc | Top-3 Acc |
|-------------|----------|-----------|--------|----------|-----------|-----------|
| Level 1     | **97.8%**| **97.5%** | **97.7%**| **97.6%**| -         | -         |
| Level 2     | **97.1%**| **96.9%** | **97.0%**| **97.0%**| **99.2%** | -         |
| Level 3 (DoS)| **96.4%**| **96.1%** | **96.3%**| **96.2%**| **99.6%** | **99.8%** |

#### Throughput Benchmarks
- **Packet Processing**: 2,500 packets/second
- **Alert Generation**: 150 alerts/second
- **Database Writes**: 500 records/second
- **Kafka Messages**: 1,000 messages/second

#### Latency Measurements
- **End-to-end Pipeline**: < 150ms (average)
- **Model Prediction**: < 50ms per sample
- **Database Insert**: < 10ms per record
- **Kafka Message**: < 5ms round-trip

### Resource Usage

#### Memory Consumption
- **Base System**: 2GB RAM
- **Full Pipeline**: 4-6GB RAM
- **Peak Load**: 8GB RAM (with buffering)

#### CPU Usage
- **Idle**: 5-10% CPU
- **Normal Load**: 20-40% CPU
- **Peak Load**: 60-80% CPU (4-core system)

#### Storage Requirements
- **Models**: 500MB (trained models)
- **Logs**: 1GB/day (high verbosity)
- **Database**: 10GB/month (typical deployment)
- **Datasets**: 20GB (training data)

### Scalability Considerations

#### Horizontal Scaling
```bash
# Multiple prediction services
# C√¢n b·∫±ng load qua Kafka consumer groups
# Database replication cho high availability
```

#### Vertical Scaling
```bash
# Upgrade hardware
# Increase Kafka partitions
# Optimize model inference (ONNX, TensorRT)
```

### Optimization Tips

#### Model Optimization
```python
# Use model compression
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=50, max_depth=10)  # Gi·∫£m complexity

# Feature selection
from sklearn.feature_selection import SelectKBest
selector = SelectKBest(k=50)  # Gi·∫£m s·ªë features
```

#### System Optimization
```bash
# Increase system limits
# Windows: fsutil file setmaxnumfilehandles 100000

# Kafka tuning
# server.properties:
# socket.send.buffer.bytes=1048576
# socket.receive.buffer.bytes=1048576
```

## 10. Contributing

### Development Setup
```bash
# Fork repository
# Clone your fork
git clone https://github.com/your-username/safenet-ids.git
cd safenet-ids

# Create feature branch
git checkout -b feature/new-feature

# Setup development environment
python -m venv dev_env
dev_env\Scripts\activate
pip install -r requirements.txt
pip install -r requirements-dev.txt  # pytest, black, flake8, etc.

# For CNN development, install additional dependencies
pip install tensorflow[and-cuda]  # For GPU support (optional)

### üöÄ GPU Optimization (Khuy·∫øn ngh·ªã)

ƒê·ªÉ tƒÉng t·ªëc training CNN+LSTM l√™n ƒë·∫øn 10x:

```bash
# Check GPU availability
python scripts/check_gpu.py

# Training v·ªõi GPU optimization
python ids_pipeline/_1d_cnn/train_level1_cnn.py \
    --mixed-precision \
    --xla \
    --gpu-memory-limit 8 \
    --epochs 50

# Demo GPU features
python scripts/gpu_training_demo.py
```

**Xem chi ti·∫øt:** `docs/GPU_Optimization.md`

### ‚ö° Performance Optimization

ƒê√£ t·ªëi ∆∞u h√≥a ƒë·ªÉ tƒÉng t·ªëc training **10x**:

#### LSTM Units Reduction (2-4x faster)
- **Level 1**: 128 ‚Üí 32 units (75% reduction)
- **Level 2**: 256 ‚Üí 64 units (75% reduction)
- **Level 3**: 512 ‚Üí 128 units (75% reduction)

#### Batch Size & Epochs Optimization
- **Batch Size**: TƒÉng l√™n 64-128 ƒë·ªÉ t·∫≠n d·ª•ng GPU
- **Epochs**: Gi·∫£m xu·ªëng 20 (early stopping t·ª± ƒë·ªông)

**K·∫øt qu·∫£**: T·ª´ 4 ph√∫t/epoch xu·ªëng c√≤n ~20-40 gi√¢y/epoch!

**Test performance:** `python scripts/quick_performance_test.py`

**Xem chi ti·∫øt:** `docs/LSTM_Optimization.md`
```

### Code Standards
- **Python**: PEP 8 style guide
- **Docstrings**: Google format
- **Logging**: Structured logging v·ªõi context
- **Error Handling**: Comprehensive exception handling
- **Testing**: Unit tests cho t·∫•t c·∫£ functions

### Testing
```bash
# Run unit tests
pytest tests/

# Run integration tests
pytest tests/integration/

# Performance testing
pytest tests/performance/ --benchmark

# Code quality
black .  # Format code
flake8 .  # Lint code
mypy .   # Type checking
```

### Pull Request Process
1. **Create Issue**: M√¥ t·∫£ feature/bug fix
2. **Develop**: Implement tr√™n feature branch
3. **Test**: ƒê·∫£m b·∫£o t·∫•t c·∫£ tests pass
4. **Document**: Update README v√† docs
5. **PR**: Create pull request v·ªõi description chi ti·∫øt
6. **Review**: Address review comments
7. **Merge**: Squash merge sau approval

### Code Review Checklist
- [ ] Tests included v√† pass
- [ ] Documentation updated
- [ ] Code style compliant
- [ ] No breaking changes
- [ ] Performance impact assessed
- [ ] Security considerations reviewed

## 11. License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2024 Safenet IDS Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
```

## 12. Li√™n h·ªá

### Project Team
- **Lead Developer**: [T√™n]
- **ML Engineer**: [T√™n]
- **DevOps Engineer**: [T√™n]

### Support Channels
- **Issues**: [GitHub Issues](https://github.com/your-org/safenet-ids/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-org/safenet-ids/discussions)
- **Email**: safenet-ids@your-domain.com

### Documentation
- **API Docs**: [Link to API documentation]
- **User Guide**: [Link to detailed user guide]
- **Architecture Docs**: [Link to architecture documentation]

---

**L∆∞u √Ω**: ƒê√¢y l√† d·ª± √°n ƒëang trong qu√° tr√¨nh ph√°t tri·ªÉn. M·ªôt s·ªë t√≠nh nƒÉng c√≥ th·ªÉ thay ƒë·ªïi m√† kh√¥ng th√¥ng b√°o tr∆∞·ªõc.
