# Safenet IDS - Kafka Services

H∆∞·ªõng d·∫´n tri·ªÉn khai v√† s·ª≠ d·ª•ng c√°c Kafka services cho h·ªá th·ªëng ph√°t hi·ªán x√¢m nh·∫≠p Safenet IDS.

## üìö Documentation Features

T·∫•t c·∫£ code trong th∆∞ m·ª•c `services/` ƒë√£ ƒë∆∞·ª£c comment chi ti·∫øt b·∫±ng ti·∫øng Vi·ªát v·ªõi:
- **Function/Class purposes**: M√¥ t·∫£ r√µ r√†ng ch·ª©c nƒÉng v√† tr√°ch nhi·ªám
- **Parameter explanations**: Gi·∫£i th√≠ch t·ª´ng tham s·ªë ƒë·∫ßu v√†o
- **Process flow**: Lu·ªìng x·ª≠ l√Ω t·ª´ng b∆∞·ªõc m·ªôt c√°ch chi ti·∫øt
- **Error handling**: C√°ch x·ª≠ l√Ω exceptions v√† edge cases
- **Integration points**: C√°ch service t∆∞∆°ng t√°c v·ªõi Kafka v√† c√°c components kh√°c

## üéØ Quick Reference

| File | Service | Input Topic | Output Topic | Purpose |
|------|---------|-------------|--------------|---------|
| `network_data_producer.py` | Network Producer | - | `raw_network_events` | Generate network traffic data |
| `data_preprocessing_service.py` | Data Preprocessing | `raw_network_events` | `preprocessed_events` | Clean & normalize data |
| `level1_prediction_service.py` | Level 1 Prediction | `preprocessed_events` | `level1_predictions` | Classify attack groups |
| `level2_prediction_service.py` | Level 2 Prediction | `level1_predictions` | `level2_predictions` | Detailed attack classification |
| `alerting_service.py` | Alerting Service | `level2_predictions` | `ids_alerts` | Generate security alerts |

## T·ªïng quan ki·∫øn tr√∫c

```
Network Data ‚Üí raw_network_events ‚Üí Data Preprocessing ‚Üí preprocessed_events ‚Üí Level 1 Prediction ‚Üí level1_predictions ‚Üí Level 2 Prediction ‚Üí level2_predictions ‚Üí Alerting ‚Üí ids_alerts
```

## C√°c Services

### 1. Network Data Producer Service (`network_data_producer.py`)
**Ch·ª©c nƒÉng**: Thu th·∫≠p d·ªØ li·ªáu network v√† g·ª≠i ƒë·∫øn Kafka
- **Input**: Kh√¥ng c√≥ (t·ª± t·∫°o sample data ho·∫∑c ƒë·ªçc t·ª´ file)
- **Output**: `raw_network_events`
- **C√°ch ch·∫°y**:
  ```bash
  python services/network_data_producer.py
  ```
- **T√πy ch·ªçn**:
  - `--historical-data`: ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV ƒë·ªÉ test
  - `--interval`: Kho·∫£ng th·ªùi gian g·ª≠i d·ªØ li·ªáu (gi√¢y)

### 2. Data Preprocessing Service (`data_preprocessing_service.py`)
**Ch·ª©c nƒÉng**: Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu network theo pipeline c·ªßa d·ª± √°n
- **Input**: `raw_network_events`
- **Output**: `preprocessed_events`
- **C√°ch ch·∫°y**:
  ```bash
  python services/data_preprocessing_service.py
  ```
- **T√≠nh nƒÉng**:
  - Chu·∫©n h√≥a t√™n c·ªôt
  - Convert numeric v√† fill missing values
  - IQR outlier clipping
  - Standard scaling
  - T·∫°o label_group

### 3. Level 1 Prediction Service (`level1_prediction_service.py`)
**Ch·ª©c nƒÉng**: Ph√¢n lo·∫°i nh√≥m attack t·ªïng qu√°t (benign/dos/ddos/portscan)
- **Input**: `preprocessed_events`
- **Output**: `level1_predictions`
- **Model**: `artifacts/ids_pipeline.joblib`
- **C√°ch ch·∫°y**:
  ```bash
  python services/level1_prediction_service.py
  ```
- **T√≠nh nƒÉng**:
  - Load model Level 1
  - Ch·∫°y prediction v·ªõi confidence scores
  - G·ª≠i k·∫øt qu·∫£ k√®m th√¥ng tin model

### 4. Level 2 Prediction Service (`level2_prediction_service.py`)
**Ch·ª©c nƒÉng**: Ph√¢n lo·∫°i chi ti·∫øt cho nh√≥m DoS (dos)
- **Input**: `level1_predictions`
- **Output**: `level2_predictions`
- **Models**: `artifacts_level2/{group}/{group}_pipeline.joblib`
- **C√°ch ch·∫°y**:
  ```bash
  python services/level2_prediction_service.py
  ```
- **T√≠nh nƒÉng**:
  - Ch·ªâ ch·∫°y Level 2 khi Level 1 detect dos
  - Load model t∆∞∆°ng ·ª©ng theo group
  - Mapping prediction sang attack types c·ª• th·ªÉ (DoS Hulk, DoS GoldenEye, DoS slowloris, DoS Slowhttptest)

### 5. Alerting Service (`alerting_service.py`)
**Ch·ª©c nƒÉng**: T·∫°o v√† qu·∫£n l√Ω alerts t·ª´ predictions
- **Input**: `level2_predictions`
- **Output**: `ids_alerts`
- **Database**: `services/data/alerts.db`
- **C√°ch ch·∫°y**:
  ```bash
  python services/alerting_service.py
  ```
- **T√≠nh nƒÉng**:
  - T·∫°o alerts d·ª±a tr√™n confidence thresholds
  - Ph√¢n lo·∫°i severity (low/medium/high/critical)
  - L∆∞u alerts v√†o SQLite database
  - G·ª≠i alerts ƒë·∫øn Kafka topic

## Kh·ªüi ƒë·ªông h·ªá th·ªëng

### C√°ch 1: Kh·ªüi ƒë·ªông t·∫•t c·∫£ services c√πng l√∫c
```bash
cd services
start_all_services.bat
```

### C√°ch 2: Kh·ªüi ƒë·ªông t·ª´ng service ri√™ng l·∫ª
```bash
# Terminal 1 - Kafka services
cd c:/kafka
start-ids-kafka.bat

# Terminal 2 - Network Producer
cd services
python network_data_producer.py

# Terminal 3 - Data Preprocessing
python data_preprocessing_service.py

# Terminal 4 - Level 1 Prediction
python level1_prediction_service.py

# Terminal 5 - Level 2 Prediction
python level2_prediction_service.py

# Terminal 6 - Alerting
python alerting_service.py
```

## C·∫•u h√¨nh

### Bi·∫øn m√¥i tr∆∞·ªùng v√† tham s·ªë m·∫∑c ƒë·ªãnh:
- **Kafka Servers**: `localhost:9092`
- **Model Paths**:
  - Level 1: `artifacts/ids_pipeline.joblib`
  - Level 2: `artifacts_level2/{group}/{group}_pipeline.joblib`
- **Database**: `services/data/alerts.db`
- **Logs**: `services/logs/`

### Thay ƒë·ªïi c·∫•u h√¨nh:
```bash
# S·ª≠ d·ª•ng Kafka servers kh√°c
python network_data_producer.py --kafka-servers kafka-cluster:9092

# Thay ƒë·ªïi model path
python level1_prediction_service.py --model-path custom_model.joblib

# Thay ƒë·ªïi database path
python alerting_service.py --db-path custom_alerts.db
```

## Monitoring v√† Debug

### Logs
T·∫•t c·∫£ logs ƒë∆∞·ª£c l∆∞u trong `services/logs/`:
- `network_producer.log`
- `data_preprocessing.log`
- `level1_prediction.log`
- `level2_prediction.log`
- `alerting.log`

### Ki·ªÉm tra ho·∫°t ƒë·ªông Kafka
```bash
# Ki·ªÉm tra topics
bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092

# Monitor messages
bin\windows\kafka-console-consumer.bat --topic ids_alerts --from-beginning --bootstrap-server localhost:9092
```

### Ki·ªÉm tra database alerts
```bash
# S·ª≠ d·ª•ng SQLite browser ho·∫∑c command line
sqlite3 services/data/alerts.db "SELECT * FROM alerts LIMIT 10;"
```

## Alert Thresholds

C·∫•u h√¨nh ng∆∞·ª°ng confidence ƒë·ªÉ t·∫°o alert (trong `alerting_service.py`):

```python
alert_thresholds = {
    'benign': 0.0,      # Kh√¥ng t·∫°o alert
    'dos': 0.7,         # 70% confidence
    'ddos': 0.6,        # 60% confidence
    'portscan': 0.65,   # 65% confidence
    'default': 0.7      # M·∫∑c ƒë·ªãnh 70%
}
```

## Troubleshooting

### Service kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c Kafka
- Ki·ªÉm tra Kafka ƒëang ch·∫°y: `start-ids-kafka.bat`
- Ki·ªÉm tra ports: `netstat -an | find "9092"`
- Ki·ªÉm tra logs Kafka trong `c:/kafka/logs/`

### Model kh√¥ng load ƒë∆∞·ª£c
- Ki·ªÉm tra file model t·ªìn t·∫°i: `dir artifacts\`
- Ki·ªÉm tra dependencies: `pip install -r requirements.txt`
- Ki·ªÉm tra logs service t∆∞∆°ng ·ª©ng

### Kh√¥ng c√≥ alerts ƒë∆∞·ª£c t·∫°o
- Ki·ªÉm tra confidence scores trong logs
- Ki·ªÉm tra thresholds trong alerting service
- Ki·ªÉm tra database: `sqlite3 services/data/alerts.db "SELECT COUNT(*) FROM alerts;"`

## Performance Tuning

### Kafka Configuration
- TƒÉng `num.partitions` trong `server.properties` cho throughput cao h∆°n
- ƒêi·ªÅu ch·ªânh `batch.size` v√† `linger.ms` trong producer properties

### Service Configuration
- TƒÉng `max_poll_records` trong consumer ƒë·ªÉ x·ª≠ l√Ω nhi·ªÅu messages c√πng l√∫c
- ƒêi·ªÅu ch·ªânh `buffer_memory` trong producer cho memory usage

### Database Optimization
- Th√™m indexes cho c√°c tr∆∞·ªùng th∆∞·ªùng query
- Implement cleanup policy cho alerts c≈©

## M·ªü r·ªông

### Th√™m Data Sources
S·ª≠a `network_data_producer.py` ƒë·ªÉ:
- ƒê·ªçc t·ª´ PCAP files
- K·∫øt n·ªëi network interfaces
- T√≠ch h·ª£p v·ªõi SIEM systems

### Custom Alert Actions
S·ª≠a `alerting_service.py` ƒë·ªÉ:
- G·ª≠i email/SMS alerts
- T√≠ch h·ª£p v·ªõi ticketing systems
- Trigger automated responses

### Dashboard Integration
- K·∫øt n·ªëi v·ªõi Grafana ƒë·ªÉ visualize alerts
- T√≠ch h·ª£p v·ªõi Elasticsearch/Kibana stack
- Real-time monitoring dashboard
