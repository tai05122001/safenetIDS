"""
Script hu·∫•n luy·ªán Intrusion Detection Model Level 2 - Attack Types ch·ªâ v·ªõi Random Forest.

Level 2: Ph√¢n lo·∫°i lo·∫°i t·∫•n c√¥ng (dos, ddos, portscan)
Ch·ªâ ch·∫°y khi Level 1 = attack

Pipeline ch√≠nh:
1. ƒê·∫£m b·∫£o d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c split (t·ª± ch·∫°y scripts/split_dataset.py level 2 n·∫øu c·∫ßn).
2. ƒê·ªçc c√°c t·∫≠p train_raw/train_balanced/val/test (ch·ªâ c√°c samples l√† attack).
3. S·ª≠ d·ª•ng label_attack_type_encoded (0=dos, 1=ddos, 2=portscan).
4. Hu·∫•n luy·ªán Random Forest model.
5. ƒê√°nh gi√° tr√™n validation v√† holdout/test.
6. L∆∞u artefact (joblib, metrics, metadata).

V√≠ d·ª• ch·∫°y:
python ids_pipeline/train_level2_attack_types_rf.py \
    --splits-dir dataset/splits/level2 \
    --train-variant balanced \
    --output-dir artifacts_level2_attack_types_rf
"""
from __future__ import annotations

# ==================== IMPORTS ====================
import argparse
import json
import logging
from typing import Dict, List, Tuple
from pathlib import Path
import subprocess
import sys
import joblib
import numpy as np
import pandas as pd

# Sklearn imports
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier


def make_json_safe(value):
    """Chuy·ªÉn ƒë·ªïi c√°c ki·ªÉu numpy th√†nh ki·ªÉu Python native ƒë·ªÉ l∆∞u JSON."""
    if isinstance(value, dict):
        return {make_json_safe(k): make_json_safe(v) for k, v in value.items()}
    if isinstance(value, list):
        return [make_json_safe(v) for v in value]
    if isinstance(value, tuple):
        return [make_json_safe(v) for v in value]
    if isinstance(value, (np.integer,)):
        return int(value)
    if isinstance(value, (np.floating,)):
        return float(value)
    if isinstance(value, (np.ndarray,)):
        return make_json_safe(value.tolist())
    return value


def parse_args() -> argparse.Namespace:
    """ƒê·ªãnh nghƒ©a v√† parse tham s·ªë d√≤ng l·ªánh."""
    parser = argparse.ArgumentParser(
        description="Hu·∫•n luy·ªán m√¥ h√¨nh IDS Level 2 - Attack Types v·ªõi Random Forest."
    )
    parser.add_argument(
        "--splits-dir",
        type=Path,
        default=Path("dataset/splits/level2"),
        help="Th∆∞ m·ª•c ch·ª©a c√°c t·∫≠p d·ªØ li·ªáu ƒë√£ chia s·∫µn (m·∫∑c ƒë·ªãnh: dataset/splits/level2).",
    )
    parser.add_argument(
        "--source-dataset",
        type=Path,
        default=Path("dataset_clean_rf.pkl"),
        help="Dataset ngu·ªìn d√πng ƒë·ªÉ split level 2 n·∫øu ch∆∞a c√≥ (m·∫∑c ƒë·ªãnh: dataset_clean_rf.pkl).",
    )
    parser.add_argument(
        "--train-variant",
        choices=["raw", "balanced"],
        default="balanced",
        help="Ch·ªçn train_raw hay train_balanced ƒë·ªÉ hu·∫•n luy·ªán (m·∫∑c ƒë·ªãnh: balanced).",
    )
    parser.add_argument(
        "--label-column",
        default="label_attack_type_encoded",
        help="T√™n c·ªôt nh√£n d√πng cho training (m·∫∑c ƒë·ªãnh: label_attack_type_encoded).",
    )
    parser.add_argument(
        "--drop-columns",
        nargs="*",
        default=["label_group", "label", "label_group_encoded", "label_binary_encoded"],
        help="Danh s√°ch c·ªôt b·ªè qua khi hu·∫•n luy·ªán (tr√°nh data leakage t·ª´ Level 1).",
    )
    parser.add_argument(
        "--test-size",
        type=float,
        default=None,
        help="(Tu·ª≥ ch·ªçn) t√°ch l·∫°i train_raw th√†nh train/test n·∫øu mu·ªën (debug).",
    )
    parser.add_argument(
        "--random-state",
        type=int,
        default=42,
        help="Seed t√°i l·∫≠p k·∫øt qu·∫£.",
    )
    parser.add_argument(
        "--sample-frac",
        type=float,
        default=None,
        help="N·∫øu mu·ªën d√πng m·ªôt ph·∫ßn train ƒë·ªÉ th·ª≠ nghi·ªám (0 < frac ‚â§ 1).",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path("artifacts_level2_attack_types_rf"),
        help="Th∆∞ m·ª•c l∆∞u artefact (m√¥ h√¨nh, b√°o c√°o, metadata).",
    )
    parser.add_argument(
        "--auto-split",
        action="store_true",
        default=True,
        help="T·ª± ƒë·ªông ch·∫°y split_dataset.py level 2 n·∫øu ch∆∞a th·∫•y d·ªØ li·ªáu (m·∫∑c ƒë·ªãnh b·∫≠t).",
    )
    parser.add_argument(
        "--no-auto-split",
        dest="auto_split",
        action="store_false",
        help="T·∫Øt t·ª± ƒë·ªông split level 2.",
    )
    parser.add_argument(
        "--split-script",
        type=Path,
        default=Path("scripts/split_dataset.py"),
        help="ƒê∆∞·ªùng d·∫´n script split_dataset.py (m·∫∑c ƒë·ªãnh: scripts/split_dataset.py).",
    )
    parser.add_argument(
        "--n-estimators",
        type=int,
        default=300,
        help="S·ªë l∆∞·ª£ng decision trees trong Random Forest (m·∫∑c ƒë·ªãnh: 300).",
    )
    parser.add_argument(
        "--max-depth",
        type=int,
        default=None,
        help="ƒê·ªô s√¢u t·ªëi ƒëa c·ªßa tree (None = kh√¥ng gi·ªõi h·∫°n, m·∫∑c ƒë·ªãnh: None).",
    )
    parser.add_argument(
        "--min-samples-split",
        type=int,
        default=2,
        help="S·ªë m·∫´u t·ªëi thi·ªÉu ƒë·ªÉ split node (m·∫∑c ƒë·ªãnh: 2).",
    )
    parser.add_argument(
        "--min-samples-leaf",
        type=int,
        default=1,
        help="S·ªë m·∫´u t·ªëi thi·ªÉu ·ªü leaf node (m·∫∑c ƒë·ªãnh: 1).",
    )
    return parser.parse_args()


def setup_logging() -> None:
    """C·∫•u h√¨nh logging m·ª©c INFO v√† ƒë·ªãnh d·∫°ng th·ªëng nh·∫•t."""
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s | %(levelname)8s | %(message)s",
    )


def load_split_dataframe(
    path: Path, sample_frac: float | None, random_state: int
) -> pd.DataFrame:
    """ƒê·ªçc DataFrame t·ª´ pickle/CSV v√† (tu·ª≥ ch·ªçn) sample m·ªôt ph·∫ßn d·ªØ li·ªáu."""
    if not path.exists():
        raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu t·∫°i {path}")

    logging.info("ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ %s", path)
    suffix = path.suffix.lower()
    
    if suffix in {".pkl", ".pickle"}:
        df = pd.read_pickle(path)
    elif suffix == ".csv":
        df = pd.read_csv(path)
    else:
        raise ValueError(f"ƒê·ªãnh d·∫°ng d·ªØ li·ªáu kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {suffix}")

    if not isinstance(df, pd.DataFrame):
        raise TypeError("Dataset ph·∫£i l√† pandas DataFrame sau khi ƒë·ªçc.")

    if sample_frac is not None:
        if not 0 < sample_frac <= 1:
            raise ValueError("--sample-frac ph·∫£i n·∫±m trong (0, 1].")
        df = df.sample(frac=sample_frac, random_state=random_state).reset_index(drop=True)
        logging.info("Sample %.2f => %d rows.", sample_frac, df.shape[0])
    else:
        logging.info("Dataset c√≥ %d d√≤ng, %d c·ªôt.", df.shape[0], df.shape[1])
    return df


def prepare_features_labels(
    df: pd.DataFrame, label_column: str, drop_columns: List[str]
) -> Tuple[pd.DataFrame, pd.Series, str, List[str]]:
    """T√°ch features (X) v√† labels (y) t·ª´ DataFrame."""
    column_lookup = {col.lower(): col for col in df.columns}
    
    label_key = label_column.lower()
    if label_key not in column_lookup:
        raise KeyError(f"Kh√¥ng t√¨m th·∫•y c·ªôt nh√£n '{label_column}' trong dataset.")
    label_actual = column_lookup[label_key]

    resolved_drop_cols: List[str] = []
    for col in drop_columns:
        key = col.lower()
        if key == label_key:
            continue
        if key in column_lookup:
            resolved_drop_cols.append(column_lookup[key])

    if resolved_drop_cols:
        logging.info("B·ªè c√°c c·ªôt kh√¥ng s·ª≠ d·ª•ng: %s", resolved_drop_cols)

    features = df.drop(columns=[label_actual] + resolved_drop_cols, errors="ignore")
    labels = df[label_actual]
    
    if not np.issubdtype(labels.dtype, np.number):
        labels = labels.astype(str)

    logging.info("Sau khi x·ª≠ l√Ω: %d features.", features.shape[1])
    return features, labels, label_actual, resolved_drop_cols


def build_preprocess_transformer(features: pd.DataFrame) -> ColumnTransformer:
    """
    T·∫°o preprocessor x·ª≠ l√Ω c·∫£ c·ªôt s·ªë v√† c·ªôt ph√¢n lo·∫°i.
    
    ‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG V·ªÄ SCALING:
    - Pipeline n√†y c√≥ StandardScaler ƒë·ªÉ scale data khi training
    - Dataset ƒë·∫ßu v√†o (dataset_clean_rf.pkl) ƒë√£ ƒë∆∞·ª£c scale s·∫µn (standard scaling)
    - N·∫øu dataset ƒë√£ ƒë∆∞·ª£c scale trong preprocess_dataset.py ‚Üí DOUBLE SCALING ‚Üí k·∫øt qu·∫£ SAI!
    - ‚Üí Lu√¥n s·ª≠ d·ª•ng --scale-method none trong preprocess_dataset.py
    """
    numeric_columns = features.select_dtypes(include=[np.number]).columns.tolist()
    categorical_columns = [col for col in features.columns if col not in numeric_columns]

    logging.info(
        "Ph√°t hi·ªán %d c·ªôt s·ªë, %d c·ªôt ph√¢n lo·∫°i.",
        len(numeric_columns),
        len(categorical_columns),
    )
    logging.info(
        "‚ö†Ô∏è  L∆ØU √ù: Model pipeline s·∫Ω t·ª± scale data (StandardScaler). "
        "Dataset ƒë·∫ßu v√†o KH√îNG n√™n ƒë∆∞·ª£c scale s·∫µn!"
    )

    numeric_pipeline = Pipeline(
        steps=[
            ("imputer", SimpleImputer(strategy="median")),
            ("scaler", StandardScaler()),
        ]
    )
    
    categorical_pipeline = Pipeline(
        steps=[
            ("imputer", SimpleImputer(strategy="most_frequent")),
            (
                "encoder",
                OneHotEncoder(
                    handle_unknown="ignore",
                    sparse_output=False,
                ),
            ),
        ]
    )
    
    return ColumnTransformer(
        transformers=[
            ("num", numeric_pipeline, numeric_columns),
            ("cat", categorical_pipeline, categorical_columns),
        ]
    )


def build_model_pipeline(
    preprocessor: ColumnTransformer,
    n_estimators: int = 300,
    max_depth: int | None = None,
    min_samples_split: int = 2,
    min_samples_leaf: int = 1,
    y_train: pd.Series | None = None,
) -> Tuple[Pipeline, Dict[int, float] | None]:
    """
    X√¢y d·ª±ng pipeline g·ªìm preprocessor + Random Forest classifier.
    
    Level 2: Attack Types classification
    Classes: 0=dos, 1=ddos, 2=portscan
    """
    # Custom class weights cho attack types
    class_weights = {
        0: 1.5,   # dos
        1: 1.5,   # ddos
        2: 1.5,   # portscan
    }
    
    # N·∫øu c√≥ y_train, t√≠nh to√°n class weights ƒë·ªông d·ª±a tr√™n distribution
    if y_train is not None:
        from sklearn.utils.class_weight import compute_class_weight
        import numpy as np
        
        classes = np.unique(y_train)
        # T√≠nh weights c∆° b·∫£n t·ª´ distribution
        computed_weights = compute_class_weight('balanced', classes=classes, y=y_train)
        computed_dict = dict(zip(classes, computed_weights))
        
        # ƒêi·ªÅu ch·ªânh: TƒÉng th√™m weight cho t·∫•t c·∫£ attack types
        for cls in classes:
            computed_dict[cls] = computed_dict[cls] * 1.2  # TƒÉng 20%
        
        # Merge v·ªõi default weights
        for cls, weight in class_weights.items():
            if cls not in computed_dict:
                computed_dict[cls] = weight
        
        class_weights = computed_dict
        logging.info(f"Computed class weights for attack types: {class_weights}")
    else:
        logging.info(f"Using default class weights: {class_weights}")
    
    classifier = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        min_samples_leaf=min_samples_leaf,
        n_jobs=-1,
        random_state=42,
        class_weight=class_weights,
    )
    
    logging.info(
        "Random Forest config: n_estimators=%d, max_depth=%s, min_samples_split=%d, min_samples_leaf=%d",
        n_estimators,
        max_depth if max_depth else "None",
        min_samples_split,
        min_samples_leaf,
    )
    logging.info(f"Class weights: {class_weights}")
    
    pipeline = Pipeline(steps=[("preprocess", preprocessor), ("classifier", classifier)])
    
    # Tr·∫£ v·ªÅ c·∫£ pipeline v√† class_weights ƒë·ªÉ l∆∞u v√†o metadata
    final_weights = class_weights if isinstance(class_weights, dict) else None
    return pipeline, final_weights


def evaluate_model(
    model: Pipeline, X_eval: pd.DataFrame, y_eval: pd.Series
) -> Dict[str, Dict[str, float]]:
    """ƒê√°nh gi√° model tr√™n t·∫≠p d·ªØ li·ªáu evaluation v√† tr·∫£ v·ªÅ metrics."""
    logging.info("ƒêang ƒë√°nh gi√° m√¥ h√¨nh...")
    y_pred = model.predict(X_eval)
    
    report = classification_report(y_eval, y_pred, output_dict=True, zero_division=0)
    conf_mtx = confusion_matrix(y_eval, y_pred)
    
    logging.info("Classification report:\n%s", json.dumps(report, indent=2))
    logging.info("Confusion matrix:\n%s", conf_mtx)
    
    return {
        "classification_report": report,
        "confusion_matrix": conf_mtx.tolist(),
    }


def save_artifacts(
    model: Pipeline,
    metrics: Dict[str, Dict[str, float]],
    output_dir: Path,
    metadata: Dict[str, str | int | float],
) -> None:
    """L∆∞u c√°c artifacts: model, metrics, metadata."""
    output_dir.mkdir(parents=True, exist_ok=True)
    
    model_path = output_dir / "ids_pipeline_level2_attack_types_rf.joblib"
    metrics_path = output_dir / "metrics.json"
    metadata_path = output_dir / "metadata.json"

    joblib.dump(model, model_path)
    logging.info("ƒê√£ l∆∞u pipeline v√†o %s", model_path)

    metrics_path.write_text(json.dumps(make_json_safe(metrics), indent=2), encoding="utf-8")
    logging.info("ƒê√£ l∆∞u metrics v√†o %s", metrics_path)

    metadata_path.write_text(json.dumps(make_json_safe(metadata), indent=2), encoding="utf-8")
    logging.info("ƒê√£ l∆∞u metadata v√†o %s", metadata_path)


def main() -> None:
    """H√†m main: ƒêi·ªÉm v√†o ch√≠nh c·ªßa script."""
    args = parse_args()
    setup_logging()

    run_training_pipeline(
        splits_dir=args.splits_dir,
        source_dataset=args.source_dataset,
        auto_split=args.auto_split,
        split_script=args.split_script,
        train_variant=args.train_variant,
        label_column=args.label_column,
        drop_columns=args.drop_columns,
        test_size=args.test_size,
        random_state=args.random_state,
        sample_frac=args.sample_frac,
        output_dir=args.output_dir,
        n_estimators=args.n_estimators,
        max_depth=args.max_depth,
        min_samples_split=args.min_samples_split,
        min_samples_leaf=args.min_samples_leaf,
    )


def run_training_pipeline(
    *,
    splits_dir: Path | str,
    source_dataset: Path | str,
    auto_split: bool,
    split_script: Path | str,
    train_variant: str = "balanced",
    label_column: str = "label_attack_type_encoded",
    drop_columns: List[str] | None = None,
    test_size: float | None = None,
    random_state: int = 42,
    sample_frac: float | None = None,
    output_dir: Path | str = Path("artifacts_level2_attack_types_rf"),
    n_estimators: int = 300,
    max_depth: int | None = None,
    min_samples_split: int = 2,
    min_samples_leaf: int = 1,
) -> Dict[str, object]:
    """Ch·∫°y to√†n b·ªô quy tr√¨nh hu·∫•n luy·ªán level 2 - Attack Types v·ªõi Random Forest."""
    setup_logging()

    script_dir = Path(__file__).resolve().parent
    project_root = script_dir.parent.parent

    resolved_splits_dir = Path(splits_dir)
    if not resolved_splits_dir.is_absolute():
        resolved_splits_dir = (project_root / resolved_splits_dir).resolve()

    resolved_source_dataset = Path(source_dataset)
    if not resolved_source_dataset.is_absolute():
        resolved_source_dataset = (project_root / resolved_source_dataset).resolve()

    resolved_split_script = Path(split_script)
    if not resolved_split_script.is_absolute():
        resolved_split_script = (project_root / resolved_split_script).resolve()

    resolved_output = Path(output_dir)
    if not resolved_output.is_absolute():
        resolved_output = (project_root / resolved_output).resolve()
    
    effective_drop = drop_columns or []

    if train_variant == "raw":
        train_file = resolved_splits_dir / "train_raw.pkl"
    elif train_variant == "balanced":
        train_file = resolved_splits_dir / "train_balanced.pkl"
    else:
        raise ValueError(f"Lo·∫°i t·∫≠p d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá: {train_variant}")

    logging.info("=" * 80)
    logging.info(f"üìÅ Train variant: {train_variant}")
    logging.info(f"üìÅ Train file s·∫Ω ƒë∆∞·ª£c load: {train_file}")
    logging.info(f"üìÅ File t·ªìn t·∫°i: {train_file.exists()}")
    logging.info("=" * 80)

    required_files = [
        train_file,
        resolved_splits_dir / "val.pkl",
        resolved_splits_dir / "test.pkl",
    ]
    
    if auto_split and not all(path.exists() for path in required_files):
        logging.info(
            "Kh√¥ng th·∫•y ƒë·ªß file split t·∫°i %s, g·ªçi split_dataset.py level 2...",
            resolved_splits_dir,
        )
        cmd = [
            sys.executable,
            str(resolved_split_script),
            "--source",
            str(resolved_source_dataset),
            "--level",
            "2",
            "--label-column",
            "label_encoded",
            "--output-dir",
            str(resolved_splits_dir),
            "--train-min",
            str(10_000),
            "--train-max",
            str(200_000),
            "--random-state",
            str(random_state),
        ]
        logging.info("Ch·∫°y l·ªánh: %s", " ".join(cmd))
        subprocess.run(cmd, check=True)

    df_train = load_split_dataframe(train_file, sample_frac, random_state)
    df_val = load_split_dataframe(
        resolved_splits_dir / "val.pkl", None, random_state
    )
    df_test = load_split_dataframe(
        resolved_splits_dir / "test.pkl", None, random_state
    )

    logging.info("=" * 80)
    logging.info(f"‚úÖ ƒê√£ load training data t·ª´: {train_file}")
    logging.info(f"‚úÖ Training data shape: {df_train.shape[0]} rows x {df_train.shape[1]} cols")
    logging.info("=" * 80)

    # Log class distribution trong training data
    if label_column in df_train.columns:
        train_label_counts = df_train[label_column].value_counts().sort_index()
        logging.info("Class distribution in training data (from loaded file):")
        for label, count in train_label_counts.items():
            percentage = (count / len(df_train)) * 100
            logging.info("  Label %s: %d samples (%.2f%%)", label, count, percentage)
        
        # Ki·ªÉm tra xem c√≥ ƒë√∫ng 3 classes kh√¥ng (0=dos, 1=ddos, 2=portscan)
        unique_classes = sorted(train_label_counts.index)
        expected_classes = [0, 1, 2]
        if not all(cls in unique_classes for cls in expected_classes):
            logging.warning(
                "‚ö†Ô∏è  Attack types classification c·∫ßn 3 classes (0=dos, 1=ddos, 2=portscan). "
                "Ph√°t hi·ªán classes: %s", unique_classes
            )

    df_train_for_model = df_train
    df_holdout = df_test
    
    if test_size is not None and 0 < test_size < 1:
        df_train_for_model, df_holdout = train_test_split(
            df_train,
            test_size=test_size,
            stratify=df_train[label_column],
            random_state=random_state,
        )
        logging.info(
            "ƒê√£ t√°ch l·∫°i train th√†nh train/test v·ªõi test_size=%.2f -> train=%d, test=%d",
            test_size,
            df_train_for_model.shape[0],
            df_holdout.shape[0],
        )

    X_train, y_train, label_actual, drop_cols_resolved = prepare_features_labels(
        df_train_for_model, label_column, effective_drop
    )
    X_val, y_val, _, _ = prepare_features_labels(df_val, label_column, effective_drop)
    X_holdout, y_holdout, _, _ = prepare_features_labels(
        df_holdout, label_column, effective_drop
    )
    logging.info("S·ª≠ d·ª•ng c·ªôt nh√£n: %s", label_actual)

    preprocessor = build_preprocess_transformer(X_train)
    
    # Log class distribution trong training data
    class_counts = y_train.value_counts().sort_index()
    logging.info("Class distribution in training data:")
    for cls, count in class_counts.items():
        percentage = (count / len(y_train)) * 100
        logging.info(f"  Class {cls}: {count} samples ({percentage:.2f}%)")
    
    pipeline, used_class_weights = build_model_pipeline(
        preprocessor,
        n_estimators=n_estimators,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        min_samples_leaf=min_samples_leaf,
        y_train=y_train,
    )

    logging.info(
        "B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán Random Forest Level 2 - Attack Types (train=%d)...",
        X_train.shape[0]
    )
    pipeline.fit(X_train, y_train)
    logging.info("Hu·∫•n luy·ªán ho√†n t·∫•t.")

    metrics_val = evaluate_model(pipeline, X_val, y_val)
    metrics_holdout = evaluate_model(pipeline, X_holdout, y_holdout)

    metadata = {
        "splits_dir": str(resolved_splits_dir),
        "train_variant": train_variant,
        "train_rows": int(df_train_for_model.shape[0]),
        "val_rows": int(df_val.shape[0]),
        "test_rows": int(df_test.shape[0]),
        "holdout_rows": int(df_holdout.shape[0]),
        "label_column_requested": label_column,
        "label_column_resolved": label_actual,
        "drop_columns_requested": effective_drop,
        "drop_columns_resolved": drop_cols_resolved,
        "test_size_re_split": test_size,
        "random_state": random_state,
        "model_type": "random_forest",
        "level": 2,
        "level_description": "Attack Types (dos, ddos, portscan)",
        "n_estimators": n_estimators,
        "max_depth": max_depth,
        "min_samples_split": min_samples_split,
        "min_samples_leaf": min_samples_leaf,
        "class_labels": sorted(y_train.unique()),
        "class_distribution": {int(cls): int(count) for cls, count in class_counts.items()},
        "class_weights": {int(k): float(v) for k, v in used_class_weights.items()} if used_class_weights is not None else None,
        "label_mapping": {
            0: "dos",
            1: "ddos",
            2: "portscan"
        },
    }

    save_artifacts(
        pipeline,
        {"validation": metrics_val, "holdout": metrics_holdout},
        resolved_output,
        metadata,
    )
    logging.info("Pipeline ho√†n t·∫•t. Artefact l∆∞u t·∫°i %s", resolved_output.resolve())

    return {
        "pipeline": pipeline,
        "metrics": {"validation": metrics_val, "holdout": metrics_holdout},
        "metadata": metadata,
        "output_dir": resolved_output.resolve(),
    }


if __name__ == "__main__":
    main()

